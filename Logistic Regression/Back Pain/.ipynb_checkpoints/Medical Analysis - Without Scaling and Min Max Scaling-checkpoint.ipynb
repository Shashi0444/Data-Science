{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Same Medical data we will try to analyse with 2 different approaches here:\n",
    "    1. Without Scaling the dataset\n",
    "    2. Using Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "dataSet = pd.read_csv(\"Dataset_spine.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic data sanity and exploratory data analysis is already done in other sheet. So will skip this step here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting 13th column\n",
    "del dataSet['Unnamed: 13']\n",
    "#Naming all the columns\n",
    "dataSet.columns = ['pelvic_incidence','pelvic tilt','lumbar_lordosis_angle','sacral_slope','pelvic_radius','degree_spondylolisthesis','pelvic_slope','Direct_tilt','thoracic_slope','cervical_tilt','sacrum_angle','scoliosis_slope','Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the string value to numerical for status column\n",
    "dataSet.loc[dataSet['Status'] == 'Abnormal','Status'] = 1\n",
    "dataSet.loc[dataSet['Status'] == 'Normal','Status'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the x and y variable from dataset\n",
    "X = dataSet.loc[:,dataSet.columns != 'Status']\n",
    "y = dataSet.loc[:,dataSet.columns == 'Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries related to preprocessing:\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess_withoutScaling(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), test_size=0.3, random_state=0)  \n",
    "    # convert the y-variable data type to int :\n",
    "    y_train=y_train.astype('int')\n",
    "    y_test=y_test.astype('int')\n",
    "    return(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess_withMinMaxScaling(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), test_size=0.3, random_state=0)  \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Now apply the transformations to the data:\n",
    "    train_scaled = scaler.transform(X_train)\n",
    "    test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # convert the y-variable data type to int :\n",
    "    y_train=y_train.astype('int')\n",
    "    y_test=y_test.astype('int')\n",
    "    return(train_scaled, test_scaled, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_withoutscal, X_test_withoutscal, y_train, y_test = data_preprocess_withoutScaling(X,y)\n",
    "X_train_mimmaxscaled, X_test_minmaxscaled, y_train, y_test = data_preprocess_withMinMaxScaling(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(x,y):\n",
    "    logreg = LogisticRegression().fit(x, y)\n",
    "    return(logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Scalling - Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg_result_withoutscale = logistic_regression(X_train_withoutscal, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score : 0.87\n",
      "Testing score : 0.80\n"
     ]
    }
   ],
   "source": [
    "#print the train - test scores\n",
    "print(\"Training score : {:.2f}\".format(logreg_result_withoutscale.score(X_train_withoutscal,y_train)))\n",
    "print(\"Testing score : {:.2f}\".format(logreg_result_withoutscale.score(X_test_withoutscal,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.298731\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:567: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warn(\"Maximum Likelihood optimization failed to converge. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1354: RuntimeWarning: invalid value encountered in sqrt\n",
      "  bse_ = np.sqrt(np.diag(self.cov_params()))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1932: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.525</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>         <td>y</td>              <td>AIC:</td>         <td>153.6491</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-04-03 10:26</td>       <td>BIC:</td>         <td>194.2079</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>217</td>        <td>Log-Likelihood:</td>    <td>-64.825</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>11</td>            <td>LL-Null:</td>        <td>-136.45</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>205</td>         <td>LLR p-value:</td>    <td>3.5513e-25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>0.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>35.0000</td>             <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>               <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pelvic_incidence</th>          <td>12.8611</td>    <td>nan</td>     <td>nan</td>     <td>nan</td>    <td>nan</td>     <td>nan</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pelvic tilt</th>              <td>-12.7440</td>    <td>nan</td>     <td>nan</td>     <td>nan</td>    <td>nan</td>     <td>nan</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lumbar_lordosis_angle</th>     <td>-0.0513</td>  <td>0.0286</td>  <td>-1.7897</td> <td>0.0735</td> <td>-0.1074</td> <td>0.0049</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sacral_slope</th>             <td>-12.8725</td>    <td>nan</td>     <td>nan</td>     <td>nan</td>    <td>nan</td>     <td>nan</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pelvic_radius</th>             <td>-0.0231</td>  <td>0.0117</td>  <td>-1.9647</td> <td>0.0494</td> <td>-0.0461</td> <td>-0.0001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>degree_spondylolisthesis</th>  <td>0.1859</td>   <td>0.0320</td>  <td>5.8080</td>  <td>0.0000</td> <td>0.1232</td>  <td>0.2487</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pelvic_slope</th>              <td>0.2282</td>   <td>0.8277</td>  <td>0.2757</td>  <td>0.7828</td> <td>-1.3941</td> <td>1.8505</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Direct_tilt</th>               <td>-0.0096</td>  <td>0.0280</td>  <td>-0.3417</td> <td>0.7326</td> <td>-0.0645</td> <td>0.0453</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thoracic_slope</th>            <td>0.0518</td>   <td>0.0715</td>  <td>0.7241</td>  <td>0.4690</td> <td>-0.0883</td> <td>0.1919</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cervical_tilt</th>             <td>0.2089</td>   <td>0.0820</td>  <td>2.5488</td>  <td>0.0108</td> <td>0.0483</td>  <td>0.3696</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sacrum_angle</th>              <td>-0.0072</td>  <td>0.0188</td>  <td>-0.3833</td> <td>0.7015</td> <td>-0.0440</td> <td>0.0296</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scoliosis_slope</th>           <td>-0.0265</td>  <td>0.0223</td>  <td>-1.1877</td> <td>0.2350</td> <td>-0.0702</td> <td>0.0172</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                             Results: Logit\n",
       "=========================================================================\n",
       "Model:                  Logit              Pseudo R-squared:   0.525     \n",
       "Dependent Variable:     y                  AIC:                153.6491  \n",
       "Date:                   2021-04-03 10:26   BIC:                194.2079  \n",
       "No. Observations:       217                Log-Likelihood:     -64.825   \n",
       "Df Model:               11                 LL-Null:            -136.45   \n",
       "Df Residuals:           205                LLR p-value:        3.5513e-25\n",
       "Converged:              0.0000             Scale:              1.0000    \n",
       "No. Iterations:         35.0000                                          \n",
       "-------------------------------------------------------------------------\n",
       "                          Coef.   Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-------------------------------------------------------------------------\n",
       "pelvic_incidence          12.8611      nan     nan    nan     nan     nan\n",
       "pelvic tilt              -12.7440      nan     nan    nan     nan     nan\n",
       "lumbar_lordosis_angle     -0.0513   0.0286 -1.7897 0.0735 -0.1074  0.0049\n",
       "sacral_slope             -12.8725      nan     nan    nan     nan     nan\n",
       "pelvic_radius             -0.0231   0.0117 -1.9647 0.0494 -0.0461 -0.0001\n",
       "degree_spondylolisthesis   0.1859   0.0320  5.8080 0.0000  0.1232  0.2487\n",
       "pelvic_slope               0.2282   0.8277  0.2757 0.7828 -1.3941  1.8505\n",
       "Direct_tilt               -0.0096   0.0280 -0.3417 0.7326 -0.0645  0.0453\n",
       "thoracic_slope             0.0518   0.0715  0.7241 0.4690 -0.0883  0.1919\n",
       "cervical_tilt              0.2089   0.0820  2.5488 0.0108  0.0483  0.3696\n",
       "sacrum_angle              -0.0072   0.0188 -0.3833 0.7015 -0.0440  0.0296\n",
       "scoliosis_slope           -0.0265   0.0223 -1.1877 0.2350 -0.0702  0.0172\n",
       "=========================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.Logit(y_train,X_train_withoutscal).fit().summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without scaling it is giving warning and asking for scaling the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scalling - Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_result_withmimmaxscale = logistic_regression(X_train_mimmaxscaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score : 0.76\n",
      "Testing score : 0.73\n"
     ]
    }
   ],
   "source": [
    "#print the train - test scores\n",
    "print(\"Training score : {:.2f}\".format(logreg_result_withmimmaxscale.score(X_train_mimmaxscaled,y_train)))\n",
    "print(\"Testing score : {:.2f}\".format(logreg_result_withmimmaxscale.score(X_test_minmaxscaled,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.249223\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.604</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>         <td>y</td>              <td>AIC:</td>         <td>132.1630</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-04-03 12:58</td>       <td>BIC:</td>         <td>172.7217</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>217</td>        <td>Log-Likelihood:</td>    <td>-54.081</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>11</td>            <td>LL-Null:</td>        <td>-136.45</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>205</td>         <td>LLR p-value:</td>    <td>1.4262e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>10.0000</td>             <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th>  <th>[0.025</th>   <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>-21.0871</td>  <td>10.0725</td> <td>-2.0935</td> <td>0.0363</td> <td>-40.8287</td>  <td>-1.3454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>   <td>15.2298</td>  <td>4.6724</td>  <td>3.2596</td>  <td>0.0011</td>  <td>6.0722</td>   <td>24.3874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>   <td>-5.3262</td>  <td>3.5753</td>  <td>-1.4897</td> <td>0.1363</td> <td>-12.3336</td>  <td>1.6812</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>   <td>14.6766</td>  <td>9.9900</td>  <td>1.4691</td>  <td>0.1418</td>  <td>-4.9035</td>  <td>34.2566</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>-10.8122</td>  <td>2.7742</td>  <td>-3.8975</td> <td>0.0001</td> <td>-16.2495</td>  <td>-5.3749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>   <td>88.0711</td>  <td>14.9869</td> <td>5.8765</td>  <td>0.0000</td>  <td>58.6972</td> <td>117.4449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>   <td>-0.1943</td>  <td>0.9540</td>  <td>-0.2037</td> <td>0.8386</td>  <td>-2.0642</td>  <td>1.6755</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>   <td>-0.9588</td>  <td>1.0131</td>  <td>-0.9464</td> <td>0.3439</td>  <td>-2.9445</td>  <td>1.0268</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>   <td>-0.0087</td>  <td>1.0044</td>  <td>-0.0087</td> <td>0.9931</td>  <td>-1.9773</td>  <td>1.9598</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>  <td>1.2979</td>   <td>0.9060</td>  <td>1.4325</td>  <td>0.1520</td>  <td>-0.4779</td>  <td>3.0737</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>  <td>0.2071</td>   <td>0.8909</td>  <td>0.2325</td>  <td>0.8162</td>  <td>-1.5391</td>  <td>1.9533</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>  <td>-1.5119</td>  <td>0.9294</td>  <td>-1.6268</td> <td>0.1038</td>  <td>-3.3334</td>  <td>0.3096</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.604     \n",
       "Dependent Variable: y                AIC:              132.1630  \n",
       "Date:               2021-04-03 12:58 BIC:              172.7217  \n",
       "No. Observations:   217              Log-Likelihood:   -54.081   \n",
       "Df Model:           11               LL-Null:          -136.45   \n",
       "Df Residuals:       205              LLR p-value:      1.4262e-29\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     10.0000                                      \n",
       "-------------------------------------------------------------------\n",
       "        Coef.     Std.Err.      z      P>|z|     [0.025     0.975] \n",
       "-------------------------------------------------------------------\n",
       "x1     -21.0871    10.0725   -2.0935   0.0363   -40.8287    -1.3454\n",
       "x2      15.2298     4.6724    3.2596   0.0011     6.0722    24.3874\n",
       "x3      -5.3262     3.5753   -1.4897   0.1363   -12.3336     1.6812\n",
       "x4      14.6766     9.9900    1.4691   0.1418    -4.9035    34.2566\n",
       "x5     -10.8122     2.7742   -3.8975   0.0001   -16.2495    -5.3749\n",
       "x6      88.0711    14.9869    5.8765   0.0000    58.6972   117.4449\n",
       "x7      -0.1943     0.9540   -0.2037   0.8386    -2.0642     1.6755\n",
       "x8      -0.9588     1.0131   -0.9464   0.3439    -2.9445     1.0268\n",
       "x9      -0.0087     1.0044   -0.0087   0.9931    -1.9773     1.9598\n",
       "x10      1.2979     0.9060    1.4325   0.1520    -0.4779     3.0737\n",
       "x11      0.2071     0.8909    0.2325   0.8162    -1.5391     1.9533\n",
       "x12     -1.5119     0.9294   -1.6268   0.1038    -3.3334     0.3096\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.Logit(y_train,X_train_mimmaxscaled).fit().summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observation:\n",
    "    Not very high stardad deviation. \n",
    "    Model has converged well in 10 iterations\n",
    "    Based on P value will take the significant variables at 95% of confidence: x1, x2, x5, x6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaling - Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering only the variables which have p-value less than 0.05\n",
    "X = dataSet.loc[:,dataSet.columns != 'Status']\n",
    "y = dataSet.loc[:,dataSet.columns == 'Status']\n",
    "X_trim_1 = X.loc[:,['pelvic_incidence', 'pelvic tilt','pelvic_radius','degree_spondylolisthesis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.742\n",
      "Test set score: 0.753\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = data_preprocess_withMinMaxScaling(X_trim_1,y)\n",
    "\n",
    "logreg_result = logistic_regression(X_train_mimmaxscaled, y_train)\n",
    "\n",
    "print(\"Training set score: {:.3f}\".format(logreg_result.score(X_train_scaled,y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg_result.score(X_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.268989\n",
      "         Iterations 10\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.572     \n",
      "Dependent Variable: y                AIC:              124.7413  \n",
      "Date:               2021-04-03 14:13 BIC:              138.2609  \n",
      "No. Observations:   217              Log-Likelihood:   -58.371   \n",
      "Df Model:           3                LL-Null:          -136.45   \n",
      "Df Residuals:       213              LLR p-value:      1.2368e-33\n",
      "Converged:          1.0000           Scale:            1.0000    \n",
      "No. Iterations:     10.0000                                      \n",
      "-------------------------------------------------------------------\n",
      "        Coef.     Std.Err.      z      P>|z|     [0.025     0.975] \n",
      "-------------------------------------------------------------------\n",
      "x1     -11.7024     2.8543   -4.0999   0.0000   -17.2967    -6.1081\n",
      "x2      11.2496     2.4347    4.6205   0.0000     6.4776    16.0216\n",
      "x3      -8.9899     1.5770   -5.7004   0.0000   -12.0808    -5.8989\n",
      "x4      83.8481    13.4963    6.2127   0.0000    57.3959   110.3002\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_model=sm.Logit(y_train,X_train_scaled)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# assigning the model predicted values to y_pred\n",
    "y_pred = logreg_result.predict(X_test_scaled)\n",
    "\n",
    "# assigning the string Normal and Abnormal to the 0 and 1 values respectively. This is useful in plotting \n",
    "# the confusion matrix\n",
    "y_pred_string = y_pred.astype(str)\n",
    "y_pred_string[np.where(y_pred_string == '0')] = 'Normal'\n",
    "y_pred_string[np.where(y_pred_string == '1')] = 'Abnormal'\n",
    "\n",
    "y_test_string = y_test.astype(str)\n",
    "y_test_string[np.where(y_test_string == '0')] = 'Normal'\n",
    "y_test_string[np.where(y_test_string == '1')] = 'Abnormal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass labels=['Abnormal', 'Normal'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gauging model accuracy\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ax= plt.subplot()\n",
    "labels = ['Abnormal','Normal']\n",
    "cm = confusion_matrix(y_test_string, y_pred_string, labels)\n",
    "sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Abnormal', 'Normal']); ax.yaxis.set_ticklabels(['Abnormal', 'Normal']);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
