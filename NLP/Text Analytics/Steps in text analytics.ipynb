{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"As we have seen cases of different types of data and different ways of processing them to obtain important information out of them, in this section we will talk about one of the most sought upon data in today’s time. Customer Information is the backbone for most of the renowned companies in 21st century. Let’s take example of Google. How do you suppose Google is providing so many services for free? What profit does it make by giving you free services? Well it’s your information that google sells to different companies by analyzing your searches and makes profit through it. The moment you search for a product on google, you will start seeing the product recommendation on every website. This is the most basic usage of text analytics, product recommendation to customers by analyzing their searches. Similarly, many companies analyze the positive or negative reviews given by customers and try to predict the customer behavior. There is a wealth of such unstructured data present such as emails, google searches, online surveys, twitter, online reviews etc. which can be processed using text analysis. Many key information about people, customers can be derived by processing the unstructured text and analyzing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\verma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word tokenization\n",
    "\n",
    "word = nltk.word_tokenize(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Puncuations, stop words, number.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'seen', 'cases', 'different', 'types', 'data', 'different', 'ways', 'processing', 'obtain', 'important', 'information', 'section', 'talk', 'one', 'sought', 'upon', 'data', 'today', 'time', 'Customer', 'Information', 'backbone', 'renowned', 'companies', 'century', 'Let', 'take', 'example', 'Google', 'How', 'suppose', 'Google', 'providing', 'many', 'services', 'free', 'What', 'profit', 'make', 'giving', 'free', 'services', 'Well', 'information', 'google', 'sells', 'different', 'companies', 'analyzing', 'searches', 'makes', 'profit', 'The', 'moment', 'search', 'product', 'google', 'start', 'seeing', 'product', 'recommendation', 'every', 'website', 'This', 'basic', 'usage', 'text', 'analytics', 'product', 'recommendation', 'customers', 'analyzing', 'searches', 'Similarly', 'many', 'companies', 'analyze', 'positive', 'negative', 'reviews', 'given', 'customers', 'try', 'predict', 'customer', 'behavior', 'There', 'wealth', 'unstructured', 'data', 'present', 'emails', 'google', 'searches', 'online', 'surveys', 'twitter', 'online', 'reviews', 'etc', 'processed', 'using', 'text', 'analysis', 'Many', 'key', 'information', 'people', 'customers', 'derived', 'processing', 'unstructured', 'text', 'analyzing']\n"
     ]
    }
   ],
   "source": [
    "## Cleaning data\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "punct = string.punctuation\n",
    "cleandata = []\n",
    "for d in word:\n",
    "     if d not in stop_words:\n",
    "        if d not in punct:\n",
    "            if d.isalpha():\n",
    "                cleandata.append(d)\n",
    "print(cleandata)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('As', 'IN'), ('seen', 'VBN'), ('cases', 'NNS'), ('different', 'JJ'), ('types', 'NNS'), ('data', 'NNS'), ('different', 'JJ'), ('ways', 'NNS'), ('processing', 'VBG'), ('obtain', 'VB'), ('important', 'JJ'), ('information', 'NN'), ('section', 'NN'), ('talk', 'NN'), ('one', 'CD'), ('sought', 'NN'), ('upon', 'IN'), ('data', 'NNS'), ('today', 'NN'), ('time', 'NN'), ('Customer', 'NNP'), ('Information', 'NNP'), ('backbone', 'NN'), ('renowned', 'VBD'), ('companies', 'NNS'), ('century', 'NN'), ('Let', 'NNP'), ('take', 'VB'), ('example', 'NN'), ('Google', 'NNP'), ('How', 'NNP'), ('suppose', 'JJ'), ('Google', 'NNP'), ('providing', 'VBG'), ('many', 'JJ'), ('services', 'NNS'), ('free', 'JJ'), ('What', 'WP'), ('profit', 'NN'), ('make', 'VBP'), ('giving', 'VBG'), ('free', 'JJ'), ('services', 'NNS'), ('Well', 'NNP'), ('information', 'NN'), ('google', 'NN'), ('sells', 'VBZ'), ('different', 'JJ'), ('companies', 'NNS'), ('analyzing', 'VBG'), ('searches', 'NNS'), ('makes', 'VBZ'), ('profit', 'NN'), ('The', 'DT'), ('moment', 'NN'), ('search', 'NN'), ('product', 'NN'), ('google', 'JJ'), ('start', 'NN'), ('seeing', 'VBG'), ('product', 'NN'), ('recommendation', 'NN'), ('every', 'DT'), ('website', 'NN'), ('This', 'DT'), ('basic', 'JJ'), ('usage', 'NN'), ('text', 'NN'), ('analytics', 'NNS'), ('product', 'NN'), ('recommendation', 'NN'), ('customers', 'NNS'), ('analyzing', 'VBG'), ('searches', 'NNS'), ('Similarly', 'RB'), ('many', 'JJ'), ('companies', 'NNS'), ('analyze', 'VBP'), ('positive', 'JJ'), ('negative', 'JJ'), ('reviews', 'NNS'), ('given', 'VBN'), ('customers', 'NNS'), ('try', 'VBP'), ('predict', 'JJ'), ('customer', 'NN'), ('behavior', 'NN'), ('There', 'EX'), ('wealth', 'NN'), ('unstructured', 'VBD'), ('data', 'NNS'), ('present', 'NN'), ('emails', 'NNS'), ('google', 'VBP'), ('searches', 'NNS'), ('online', 'VBP'), ('surveys', 'NNS'), ('twitter', 'VBP'), ('online', 'JJ'), ('reviews', 'NNS'), ('etc', 'VBP'), ('processed', 'VBN'), ('using', 'VBG'), ('text', 'JJ'), ('analysis', 'NN'), ('Many', 'NNP'), ('key', 'JJ'), ('information', 'NN'), ('people', 'NNS'), ('customers', 'NNS'), ('derived', 'VBD'), ('processing', 'NN'), ('unstructured', 'JJ'), ('text', 'NN'), ('analyzing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "## POS Tagging and Chunking\n",
    "pos = nltk.pos_tag(cleandata)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  As/IN\n",
      "  seen/VBN\n",
      "  cases/NNS\n",
      "  different/JJ\n",
      "  types/NNS\n",
      "  data/NNS\n",
      "  different/JJ\n",
      "  ways/NNS\n",
      "  processing/VBG\n",
      "  obtain/VB\n",
      "  important/JJ\n",
      "  information/NN\n",
      "  section/NN\n",
      "  talk/NN\n",
      "  one/CD\n",
      "  sought/NN\n",
      "  upon/IN\n",
      "  data/NNS\n",
      "  (NEW today/NN time/NN Customer/NNP)\n",
      "  (NEW Information/NNP)\n",
      "  backbone/NN\n",
      "  renowned/VBD\n",
      "  companies/NNS\n",
      "  (NEW century/NN Let/NNP)\n",
      "  take/VB\n",
      "  (NEW example/NN Google/NNP)\n",
      "  (NEW How/NNP)\n",
      "  suppose/JJ\n",
      "  (NEW Google/NNP)\n",
      "  providing/VBG\n",
      "  many/JJ\n",
      "  services/NNS\n",
      "  free/JJ\n",
      "  What/WP\n",
      "  profit/NN\n",
      "  make/VBP\n",
      "  giving/VBG\n",
      "  free/JJ\n",
      "  services/NNS\n",
      "  (NEW Well/NNP)\n",
      "  information/NN\n",
      "  google/NN\n",
      "  sells/VBZ\n",
      "  different/JJ\n",
      "  companies/NNS\n",
      "  analyzing/VBG\n",
      "  searches/NNS\n",
      "  makes/VBZ\n",
      "  profit/NN\n",
      "  The/DT\n",
      "  moment/NN\n",
      "  search/NN\n",
      "  product/NN\n",
      "  google/JJ\n",
      "  start/NN\n",
      "  seeing/VBG\n",
      "  product/NN\n",
      "  recommendation/NN\n",
      "  every/DT\n",
      "  website/NN\n",
      "  This/DT\n",
      "  basic/JJ\n",
      "  usage/NN\n",
      "  text/NN\n",
      "  analytics/NNS\n",
      "  product/NN\n",
      "  recommendation/NN\n",
      "  customers/NNS\n",
      "  analyzing/VBG\n",
      "  searches/NNS\n",
      "  Similarly/RB\n",
      "  many/JJ\n",
      "  companies/NNS\n",
      "  analyze/VBP\n",
      "  positive/JJ\n",
      "  negative/JJ\n",
      "  reviews/NNS\n",
      "  given/VBN\n",
      "  customers/NNS\n",
      "  try/VBP\n",
      "  predict/JJ\n",
      "  customer/NN\n",
      "  behavior/NN\n",
      "  There/EX\n",
      "  wealth/NN\n",
      "  unstructured/VBD\n",
      "  data/NNS\n",
      "  present/NN\n",
      "  emails/NNS\n",
      "  google/VBP\n",
      "  searches/NNS\n",
      "  online/VBP\n",
      "  surveys/NNS\n",
      "  twitter/VBP\n",
      "  online/JJ\n",
      "  reviews/NNS\n",
      "  etc/VBP\n",
      "  processed/VBN\n",
      "  using/VBG\n",
      "  text/JJ\n",
      "  (NEW analysis/NN Many/NNP)\n",
      "  key/JJ\n",
      "  information/NN\n",
      "  people/NNS\n",
      "  customers/NNS\n",
      "  derived/VBD\n",
      "  processing/NN\n",
      "  unstructured/JJ\n",
      "  text/NN\n",
      "  analyzing/VBG)\n"
     ]
    }
   ],
   "source": [
    "my_node = \"NEW: {<NN>*<NNP>}\"\n",
    "chunk = nltk.RegexpParser(my_node)\n",
    "res = chunk.parse(pos)\n",
    "print(res)\n",
    "res.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as seen case differ type data differ way process obtain import inform section talk one sought upon data today time custom inform backbon renown compani centuri let take exampl googl how suppos googl provid mani servic free what profit make give free servic well inform googl sell differ compani analyz search make profit the moment search product googl start see product recommend everi websit this basic usag text analyt product recommend custom analyz search similar mani compani analyz posit negat review given custom tri predict custom behavior there wealth unstructur data present email googl search onlin survey twitter onlin review etc process use text analysi mani key inform peopl custom deriv process unstructur text analyz\n"
     ]
    }
   ],
   "source": [
    "##Stemming and Lematization\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snowball = SnowballStemmer('english')\n",
    "stemm = [snowball.stem(t) for t in cleandata]\n",
    "print(\" \".join(stemm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
